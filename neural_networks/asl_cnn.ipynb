{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48345f36-8263-4ed0-b769-8e9083198d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16f7bd-20ca-47e0-ada3-26098bf7b9ff",
   "metadata": {},
   "source": [
    "### split train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d140439-6222-4cf8-ade7-12ec61a330d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_name=os.listdir('asl_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf0770c-f65d-4959-ad27-e881b9874f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_images(list_of_filesname):\n",
    "    for file_name in list_of_filesname:\n",
    "        os.mkdir(f'asl_dataset_test/{file_name}')\n",
    "        path_of_images_test=random.sample(os.listdir(f'asl_dataset/{file_name}'), 17)\n",
    "        for image_path in path_of_images_test:\n",
    "            shutil.move(f'asl_dataset/{file_name}/{image_path}', f'asl_dataset_test/{file_name}/{image_path}')\n",
    "        \n",
    "test_images(files_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8614ab-7ac2-4d7a-a595-3a7708a773d2",
   "metadata": {},
   "source": [
    "### neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "723a8295-77f4-4fa5-b91d-19d21dd1d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1886 images belonging to 36 classes.\n",
      "Found 612 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator_train = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.3,\n",
    ")\n",
    "\n",
    "image_generator_test = ImageDataGenerator(\n",
    "    rescale=1./255.\n",
    ")\n",
    "\n",
    "train_data= image_generator_train.flow_from_directory(\n",
    "    'asl_dataset',\n",
    "    target_size=(500, 500),\n",
    "    class_mode='categorical',\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "test_data= image_generator_test.flow_from_directory(\n",
    "    'asl_dataset_test',\n",
    "    target_size=(500, 500),\n",
    "    class_mode='categorical',\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf046aff-ae1e-4f0e-a511-5868c203d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(500, 500, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(36, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe9aad0c-f620-4e2e-8696-691b99a890ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67d73f4f-546a-45ee-b3de-aa517baa93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c82c1dea-7f91-4b2e-a64e-34cdccdc662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mch = ModelCheckpoint('chestxray.h5', monitor='val_loss', mode='min', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56e22cdb-a026-414b-b619-dc375dee5ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "189/189 [==============================] - 6151s 33s/step - loss: 3.1622 - categorical_accuracy: 0.2603 - val_loss: 1.1216 - val_categorical_accuracy: 0.6650 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "189/189 [==============================] - 6125s 32s/step - loss: 0.9895 - categorical_accuracy: 0.6967 - val_loss: 0.7032 - val_categorical_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "189/189 [==============================] - 5799s 31s/step - loss: 0.5973 - categorical_accuracy: 0.8134 - val_loss: 0.4003 - val_categorical_accuracy: 0.8578 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "189/189 [==============================] - 5869s 31s/step - loss: 0.4436 - categorical_accuracy: 0.8515 - val_loss: 0.3628 - val_categorical_accuracy: 0.8758 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "189/189 [==============================] - 16024s 85s/step - loss: 0.3799 - categorical_accuracy: 0.8738 - val_loss: 0.3595 - val_categorical_accuracy: 0.8856 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, steps_per_epoch=len(train_data), epochs=5, validation_data=test_data, validation_steps=len(test_data), callbacks=[es, rlrop, mch])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
